#  # ğŸï¸ Turizm Projesi: Yorumlardan MekÃ¢n TÃ¼rÃ¼ EÅŸleÅŸtirme

Bu proje, Python dili ve NLTK kÃ¼tÃ¼phanesi kullanÄ±larak doÄŸal dil iÅŸleme (NLP) teknikleriyle turizm alanÄ±ndaki kullanÄ±cÄ± yorumlarÄ±nÄ± analiz etmeyi ve bu yorumlarÄ± ilgili mekÃ¢n tÃ¼rleriyle eÅŸleÅŸtirmeyi amaÃ§lamaktadÄ±r. Proje kapsamÄ±nda veri Ã¶n iÅŸleme, metin temizliÄŸi ve temel NLP sÃ¼reÃ§leri uygulanmÄ±ÅŸtÄ±r.

---

## 1. Hafta â€” Veri HazÄ±rlama ve Ã–niÅŸleme
1.1. Veri Toplama

ilk olarak otel ve restoran verilerini ayrÄ± ayrÄ± veriler Ã§ekilmiÅŸtir daha sonra bu verilerin yorum sÃ¼tunlarÄ±na ayrÄ±lmÄ±ÅŸtÄ±r.
AyÄ±rÄ±lan yorum sÃ¼tunlarÄ±nÄ± birleÅŸtirerek yeni bir csv (birlesik_yorumlar.csv) dosyasÄ±na kaydedilmiÅŸtir.
yeni csv dosyasÄ± Ã¼zerinde aÅŸaÄŸÄ±daki iÅŸlemleri uyguladÄ±m.
-Bu Ã§alÄ±ÅŸmam ise "yorumlarÄ±n_birleÅŸtirilmesi.ipynb" adlÄ± kaynak dosyasÄ±nda bulunmaktadÄ±r

1.2. Veri Ã–n Ä°ÅŸleme
Yorum verileri Ã¼zerinde gerÃ§ekleÅŸtirilen temel iÅŸlemler:

-  KÃ¼Ã§Ã¼k harfe Ã§evirme  
-  Noktalama iÅŸaretlerinin kaldÄ±rÄ±lmasÄ±  
-  Ä°ngilizce stopword (gereksiz kelimeler) temizliÄŸi  
-  Tokenizasyon (metni kelimelere ayÄ±rma)  
-  Lemmatizasyon ( Kelimeler kÃ¶klerine indirgenerek farklÄ± Ã§ekimler aynÄ± forma getirilmiÅŸtir.) 
- Stemming: Kelimenin kÃ¶kÃ¼nÃ¼ bulmak iÃ§in yapÄ±lmÄ±ÅŸtÄ±r

---

## ğŸ” Proje Ã–zeti

CSV dosyasÄ±ndan alÄ±nan yorumlar ÅŸu adÄ±mlardan geÃ§irilmiÅŸtir:

- Verinin `pandas` ile yÃ¼klenmesi ve genel incelemesi
- Eksik verilerin kontrolÃ¼
- CÃ¼mle ve kelime seviyesinde ayrÄ±ÅŸtÄ±rma (`tokenization`)
- Ä°ngilizce stopwords (nltk) ile filtreleme
- Lemmatizasyon ve stemleme iÅŸlemleriyle kelimelerin kÃ¶k formlarÄ±nÄ±n Ã§Ä±karÄ±lmasÄ±
- CÃ¼mle listesi oluÅŸturularak yapÄ±sal analiz yapÄ±lmasÄ±
- Veri Ã¶n iÅŸleme adÄ±mlarÄ±, nltk python, pandas ve re kÃ¼tÃ¼phaneleri kullanÄ±larak Python'da uygulanmÄ±ÅŸtÄ±r.

---

## ğŸ› ï¸ KullanÄ±lan Teknolojiler ve KÃ¼tÃ¼phaneler

- Python 3.10
- Jupyter Notebook
- [NLTK - Natural Language Toolkit](https://www.nltk.org/)
- pandas
- numpy
- import gensim   Word2Vec gibi kelime vektÃ¶rÃ¼ modellerini kullanmak iÃ§in.
- from gensim.models import Word2Vec  # Ã–zellikle Word2Vec modelini kullanmak iÃ§in
- import pandas as pd  # Veri Ã§erÃ§eveleri (DataFrame) ile Ã§alÄ±ÅŸmak ve CSV dosyalarÄ±nÄ± okumak iÃ§in
- import nltk  # DoÄŸal Dil Ä°ÅŸleme (NLP) gÃ¶revleri iÃ§in
- from nltk.tokenize import word_tokenize, sent_tokenize  # Metni kelimelere ve cÃ¼mlelere ayÄ±rmak iÃ§in
- from nltk.corpus import stopwords  # Stop kelimelerini (anlamsÄ±z sÄ±k kullanÄ±lan kelimeler) elde etmek iÃ§in
- from nltk.stem import WordNetLemmatizer, PorterStemmer  # Kelime kÃ¶klerini bulmak iÃ§in (lemmatize ve stem)
- from collections import Counter  # Listelerdeki elemanlarÄ±n sÄ±klÄ±ÄŸÄ±nÄ± saymak iÃ§in


---

##  2. Hafta: TF-IDF VektÃ¶rleÅŸtirme ve Word2Vec Modelleri 

Bu hafta, Ã¶n iÅŸlenmiÅŸ metin verileri hem TF-IDF yÃ¶ntemiyle vektÃ¶rleÅŸtirilecek hem de Word2Vec modeli kullanÄ±larak kelime vektÃ¶rleri elde edilecektir.

# 2.1. TF-IDF VektÃ¶rleÅŸtirme
TF-IDF (Term Frequency-Inverse Document Frequency) yÃ¶ntemi, bir metin iÃ§indeki kelimelerin Ã¶nemini Ã¶lÃ§mek iÃ§in kullanÄ±lan bir tekniktir. Bu adÄ±mda, her bir metin verisi, terim frekanslarÄ± (TF) ve ters belge frekansÄ± (IDF) kullanÄ±larak bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.
sklearn.feature_extraction.text kÃ¼tÃ¼phanesindeki TfidfVectorizer sÄ±nÄ±fÄ±, bu dÃ¶nÃ¼ÅŸÃ¼mÃ¼ gerÃ§ekleÅŸtirmek iÃ§in kullanÄ±lÄ±r.
kod klaÃ¶rÃ¼nÃ¼n iÃ§inde bulunan TF-Ä°DF' dosyasÄ±nda bu iÅŸlem gerÃ§ekleÅŸtirilmiÅŸtir. Elde edilen bulgular dosya iÃ§inde bulunmaktadÄ±r.

## 2.2. Cosine Similarity (KosinÃ¼s BenzerliÄŸi) HesaplamasÄ±
.TF-IDF vektÃ¶rleri elde edildikten sonra, metinler arasÄ±ndaki benzerliÄŸi Ã¶lÃ§mek iÃ§in Cosine 
 Similarity yÃ¶ntemi kullanÄ±lÄ±r. Bu yÃ¶ntem, iki vektÃ¶r arasÄ±ndaki aÃ§Ä±nÄ±n kosinÃ¼sÃ¼nÃ¼ hesaplayarak 
 metinlerin ne kadar benzer olduÄŸunu belirler.
.sklearn.metrics.pairwise kÃ¼tÃ¼phanesindeki cosine_similarity fonksiyonu, bu hesaplamayÄ± yapmak 
 iÃ§in kullanÄ±lÄ±r. *notebooks klaÃ¶rÃ¼nÃ¼n iÃ§inde bulunan 'TF-Ä°DF' dosyasÄ±nda bu iÅŸlem 
 gerÃ§ekleÅŸtirilmiÅŸtir. Elde edilen bulgular dosya iÃ§inde bulunmaktadÄ±r
 
## 2.3. Ä°lk CÃ¼mle iÃ§in En YÃ¼ksek TF-IDF Skorlu Kelimeler
TF-IDF vektÃ¶rleÅŸtirme iÅŸleminden sonra, her metindeki en Ã¶nemli kelimeler belirlenir. Bu, her metin iÃ§in en yÃ¼ksek TF-IDF skoruna sahip kelimelerin bulunmasÄ±yla yapÄ±lÄ±r.
Bu analiz, veri setindeki metinlerin anahtar temalarÄ±nÄ± ve Ã¶zelliklerini anlamaya yardÄ±mcÄ± olur.

## 2.4. Cosine Similarity Matrisi OluÅŸturma
TÃ¼m metinler arasÄ±ndaki Cosine Similarity skorlarÄ± bir matris iÃ§inde dÃ¼zenlenir. Bu matris, hangi metinlerin birbirine daha Ã§ok benzediÄŸini gÃ¶rselleÅŸtirmeyi ve analiz etmeyi kolaylaÅŸtÄ±rÄ±r.
Bu matris, Ã¶neri sistemleri veya benzer arÄ±za kayÄ±tlarÄ±nÄ± bulma gibi uygulamalar iÃ§in temel oluÅŸturabilir.
## 2.5. Word2Vec Modelleri EÄŸitimi
.Word2Vec modeli, kelimelerin anlamlarÄ±nÄ± vektÃ¶rler aracÄ±lÄ±ÄŸÄ±yla temsil etmeyi amaÃ§layan bir 
 tekniktir. Bu adÄ±mda, metin verilerinden kelime vektÃ¶rleri elde edilir.
.Model eÄŸitimi iÃ§in farklÄ± parametre kombinasyonlarÄ± kullanÄ±lÄ±r. Bu parametreler, modelin 
 performansÄ±nÄ± ve elde edilen vektÃ¶rlerin kalitesini etkileyebilir.
.Model eÄŸitimi kod klasÃ¶rÃ¼ iÃ§erisinde yer alan 'word2vec' dosyasÄ±nda gerÃ§ekleÅŸtirilmiÅŸtir.
.SeÃ§ilecek parametreler ÅŸunlarÄ± iÃ§eriyor:
 - Model tipi: CBOW (Continuous Bag of Words) veya Skip-gram.
  -Pencere boyutu: Bir kelimenin baÄŸlamÄ±nÄ± oluÅŸturan kelime sayÄ±sÄ±.
  -VektÃ¶r boyutu: Kelimelerin temsil edileceÄŸi vektÃ¶rlerin boyutu.
.EÄŸitilen modeller, daha sonra kullanÄ±lmak Ã¼zere dosyaya kaydedilmiÅŸtir. Dosya adlarÄ±, 
 kullanÄ±lan parametreleri iÃ§erecek ÅŸekilde dÃ¼zenlenmiÅŸtir (Ã¶rneÄŸin, "lemmatized_model_cbow_window2_dim100.model"). Elde edilen dosyalar, model  klasÃ¶rÃ¼ iÃ§erisine 
 kaydedilmiÅŸtir.
# 2.6. Model DeÄŸerlendirmesi ve KullanÄ±mÄ±
EÄŸitilen Word2Vec modelleri, kelime benzerliÄŸi, kelime analojisi gibi gÃ¶revlerde deÄŸerlendirilebilir.
Modelin performansÄ± ve elde edilen vektÃ¶rlerin kalitesi analiz edilebilir.
En iyi performansÄ± gÃ¶steren modeller, proje kapsamÄ±nda kullanÄ±lmak Ã¼zere seÃ§ilebilir.

# Word2Vec Model 

Bu proje, otel ve restoran yorumlarÄ± Ã¼zerinde **Word2Vec** modellerini eÄŸitmek ve kelime benzerliklerini analiz etmek iÃ§in tasarlanmÄ±ÅŸtÄ±r. AÅŸaÄŸÄ±da projenin temel adÄ±mlarÄ± ve aÃ§Ä±klamalarÄ± bulunmaktadÄ±r.

---

## AdÄ±mlar

### 1. Gerekli KÃ¼tÃ¼phanelerin Kurulumu
- **KullanÄ±lan AraÃ§lar**: `gensim` (Word2Vec modeli iÃ§in), `pandas` (veri iÅŸleme), `nltk` (metin iÅŸleme).
- **NLTK Paketleri**: Tokenizasyon, stopwords'ler ve lemmatization iÃ§in gerekli paketler indirilir.

### 2. Veri Setinin HazÄ±rlanmasÄ±
- **Veri KaynaklarÄ±**: 
  - `lemmatized_sentences.csv`: Kelimelerin kÃ¶k hallerini iÃ§eren cÃ¼mleler.
  - `stemmed_sentences.csv`: Kelime kÃ¶klerini iÃ§eren cÃ¼mleler.
- **Temizlik Ä°ÅŸlemleri**:
  - NaN ve boÅŸ deÄŸerler temizlenir.
  - Metinler Ã¶zel karakterlerden arÄ±ndÄ±rÄ±lÄ±r, kÃ¼Ã§Ã¼k harfe Ã§evrilir.
  - Stopwords'ler ve tek karakterli kelimeler filtrelenir.

### 3. Veri Analizi ve VektÃ¶rleÅŸtirme
- **Model Parametreleri**:
  - **Model TÃ¼rÃ¼**: CBOW veya Skip-gram.
  - **Pencere Boyutu**: 2 veya 4.
  - **VektÃ¶r Boyutu**: 100 veya 300.
- **EÄŸitim**:
  - Her parametre kombinasyonu iÃ§in ayrÄ± modeller eÄŸitilir.
  - Modeller `.model` uzantÄ±sÄ±yla kaydedilir.
- **Analiz**:
  - "soup" kelimesine en benzer 3 kelime ve skorlarÄ± Ã§Ä±karÄ±lÄ±r.
  - Veri setindeki en sÄ±k kullanÄ±lan 20 kelime listelenir.

---

## SonuÃ§lar
- **Kaydedilen Modeller**: `lemmatized_model_cbow_vs100_w2.model`, `stemmed_model_skipgram_vs300_w4.model` gibi isimlerle kaydedilir.
- **Ã–rnek Ã‡Ä±ktÄ±lar**:
  - Kelime benzerlikleri yÃ¼ksek skorlarla raporlanÄ±r (Ã¶rneÄŸin, "soup" â†” "burger": 0.9964).
  - En sÄ±k kullanÄ±lan kelimeler "good", "staff", "room" gibi tematik terimlerdir.

---

## NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r?
1. **Veri YollarÄ±nÄ± GÃ¼ncelleyin**: CSV dosyalarÄ±nÄ±n doÄŸru konumunu belirtin.
2. **Jupyter Not Defterini BaÅŸlatÄ±n**: TÃ¼m hÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n.
3. **SonuÃ§larÄ± GÃ¶rÃ¼ntÃ¼leyin**: Modeller ve analiz Ã§Ä±ktÄ±larÄ± otomatik olarak oluÅŸturulur.

---



 
